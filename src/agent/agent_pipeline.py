"""Agent-based IQS Search Pipeline
ì „ì²´ ì‹œìŠ¤í…œ í†µí•© ë° ì‹¤í–‰ (Kiwi Preprocessor í†µí•©ë¨)
"""
from typing import Dict, Any, List, Optional
import time
import json
from pathlib import Path

# ê¸°ì¡´ ëª¨ë“ˆ ìž„í¬íŠ¸

from src.agent.langgraph_agent import LangGraphIQSAgent
from src.agent.llm_client import LLMClientFactory
from src.data_pipeline.excel_loader import ExcelDataLoader
from src.utils.logger import log
from config.settings import settings

# Preprocessor ìž„í¬íŠ¸

try:
    from src.agent.preprocessor import preprocessor
except ImportError:
    log.warning("KiwiPreprocessor not found. Skipping preprocessing step.")
    preprocessor = None

class AgentPipeline:
    """
    LangGraph Agentì˜ íŽ¸ì˜ ëž˜í¼ í´ëž˜ìŠ¤ + ì „ì²˜ë¦¬(Preprocessing) í†µí•©
    """

    def __init__(self,
                 llm_type: str = "h-chat",
                 use_cache: bool = True):
        self.llm_type = llm_type
        self.use_cache = use_cache

        # LangGraph Agent ì´ˆê¸°í™”
        self.agent = LangGraphIQSAgent(llm_type=llm_type)

        # Pipeline ì „ìš© ê¸°ëŠ¥
        self.execution_history = []
        self.data_loaded = False
        self.documents = []

        log.info(f"Initialized AgentPipeline with Kiwi Preprocessor support")

    def load_data(self, excel_path: Optional[str] = None, force_reload: bool = False):
        """ë°ì´í„° ë¡œë“œ ë° ì¸ë±ì‹± (ê¸°ì¡´ê³¼ ë™ì¼)"""
        if self.data_loaded and not force_reload:
            log.info("Data already loaded, skipping")
            return

        log.info("Loading data for Agent pipeline")
        loader = ExcelDataLoader(excel_path)
        loader.load_excel()
        loader.clean_data()
        documents = loader.process_for_indexing()

        # ë¬¸ì„œ ì¸ë±ì‹± ìœ„ìž„
        if hasattr(self.agent, 'build_search_index'):
            self.agent.build_search_index(documents)

        self.data_loaded = True
        self.documents = documents
        log.info(f"Loaded {len(documents)} documents")

    def process_query(self, query: str, thread_id: Optional[str] = None) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ ì²˜ë¦¬ - Kiwi ì „ì²˜ë¦¬ + Agent ì‹¤í–‰
        """
        start_time = time.time()
        log.info(f"Processing query: {query}")

        # ðŸ†• 1. Kiwi ì „ì²˜ë¦¬ ë° ì—”í‹°í‹° ì¶”ì¶œ
        # ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë¶„ì„í•´ 'ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        enhanced_query = query
        extracted_entities = {}

        if preprocessor:
            try:
                # ì—”í‹°í‹°(ì°¨ì¢…, ì—°ì‹, ì½”ë“œ) ì¶”ì¶œ
                extracted_entities = preprocessor.extract_entities(query)
                keywords = preprocessor.extract_keywords(query)

                log.info(f"Kiwi extracted: {extracted_entities}")

                # LLMì—ê²Œ ížŒíŠ¸ë¥¼ ì£¼ê¸° ìœ„í•œ ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                system_hint = "\\n\\n[System Context from Database]\\n"
                has_hint = False

                if extracted_entities.get('model'):
                    system_hint += f"- Target Vehicle Model: {extracted_entities['model']}\\n"
                    has_hint = True
                if extracted_entities.get('year'):
                    system_hint += f"- Target Model Year: {extracted_entities['year']}\\n"
                    has_hint = True
                if extracted_entities.get('codes'):
                    codes_str = ", ".join(extracted_entities['codes'])
                    system_hint += f"- Detected Trouble Codes: {codes_str}\\n"
                    has_hint = True

                # ížŒíŠ¸ê°€ ìžˆì„ ê²½ìš°ì—ë§Œ ì¿¼ë¦¬ì— ì¶”ê°€
                if has_hint:
                    system_hint += "- Use these detected entities for filtering and searching."
                    enhanced_query = f"{query}{system_hint}"
                    log.info("Query enhanced with system hints")

            except Exception as e:
                log.warning(f"Preprocessing failed: {e}")

        try:
            # 2. Agent ì‹¤í–‰ (í–¥ìƒëœ ì¿¼ë¦¬ ì „ë‹¬)
            if not thread_id:
                thread_id = f"pipeline_{int(time.time())}"

            log.info(f"Delegating to Agent with query len={len(enhanced_query)}")

            agent_result = self.agent.process_query(
                query=enhanced_query,  # ížŒíŠ¸ê°€ í¬í•¨ëœ ì¿¼ë¦¬ ì „ë‹¬
                thread_id=thread_id
            )

            # 3. ê²°ê³¼ í›„ì²˜ë¦¬ (Pipeline ê¸°ëŠ¥)
            final_output = self._enhance_agent_result(agent_result)
            execution_time = time.time() - start_time

            response = {
                "success": True,
                "query": query,
                "enhanced_query": enhanced_query if enhanced_query != query else None,
                "extracted_entities": extracted_entities, # ì¶”ì¶œëœ ì—”í‹°í‹° ì •ë³´ í¬í•¨
                "thread_id": thread_id,
                "result": final_output,
                "execution_time": round(execution_time, 2),
                "agent_info": {
                    "steps_executed": agent_result.get("steps_executed", 0),
                    "tools_used": agent_result.get("tools_used", [])
                },
                "trace": self._create_pipeline_trace(agent_result)
            }

            self._add_to_history(response)
            self._last_result = response

            return response

        except Exception as e:
            log.error(f"Query processing failed: {e}")
            return {
                "success": False,
                "query": query,
                "error": str(e),
                "execution_time": round(time.time() - start_time, 2)
            }

    # ... (ë‚˜ë¨¸ì§€ ë©”ì„œë“œ _enhance_agent_result, _create_pipeline_trace ë“±ì€ ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    # ê¸°ì¡´ ì½”ë“œì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ê·¸ëŒ€ë¡œ ë‘ì…”ë„ ë©ë‹ˆë‹¤.

    def _enhance_agent_result(self, agent_result: Dict[str, Any]) -> Dict[str, Any]:
        """(ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        if not agent_result or not isinstance(agent_result, dict):
            return {"error": "Invalid agent result"}

        if agent_result.get("success"):
            return {
                "agent_result": agent_result,
                "final_answer": agent_result.get("final_synthesis") or agent_result.get("search_results")
            }
        else:
            return {"error": agent_result.get("error"), "agent_result": agent_result}

    def _create_pipeline_trace(self, agent_result: Dict[str, Any]) -> List[Dict]:
        """(ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        # ... (ìƒëžµ, ê¸°ì¡´ê³¼ ë™ì¼)
        return []

    def _add_to_history(self, response: Dict[str, Any]):
        """(ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        self.execution_history.append({
            "timestamp": time.time(),
            "query": response.get("query"),
            "success": response.get("success")
        })

    def get_statistics(self) -> Dict[str, Any]:
        """(ê¸°ì¡´ ì½”ë“œ ìœ ì§€)"""
        return {"total": len(self.execution_history)}