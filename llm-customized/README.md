# Hyundai RAG

## ğŸ“Œ ì£¼ìš” ê¸°ëŠ¥

- Retrievers
- Consistency Check
- Evaluation

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```bash
project/
â”œâ”€â”€ configs/*.yaml          # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„¤ì •
â”œâ”€â”€ datasets/               # ë°ì´í„° ì €ì¥ ê³µê°„ (RECOMMENDED)
â”œâ”€â”€ embeddings/             # embedë¥¼ ìˆ˜í–‰ ê°€ëŠ¥í•œ embedding class ì •ì˜
â”œâ”€â”€ kiwi_custom/            # customized kiwi
â”œâ”€â”€ llms/                   # invokeë¥¼ ìˆ˜í–‰ ê°€ëŠ¥í•œ chatmodel class ì •ì˜
â”œâ”€â”€ results/                # evaluation ìˆ˜í–‰ ê²°ê³¼ json í˜•íƒœë¡œ ì €ì¥
â”œâ”€â”€ retrievers/             # similarity_search_with_scoreë¥¼ ìˆ˜í–‰ ê°€ëŠ¥í•œ retriever class ì •ì˜
â”œâ”€â”€ template/               # llms ëª¨ë¸ ì¡°ì •ì„ ìœ„í•œ template
â”œâ”€â”€ utils 
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ consistency.py      # llm ëª¨ë¸ ì¼ê´€ì„± í‰ê°€ë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ load_retriever.py   # configë¥¼ í†µí•´ retriever ìƒì„±ì„ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ metrics.py          # retriever, reranker ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•œ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€preprocess.py       # ê¸°íƒ€
â”œâ”€â”€ configs/*.yaml       # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ì„¤ì •
â”œâ”€â”€ requirements.txt     # í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ README.md
â””â”€â”€ ...
```

1. ì„¤ì¹˜

# miniconda env
```bash
conda create -n {env_name} python==3.12
```

# mecab ë³„ë„ ì„¤ì¹˜
```bash
conda install -c conda-forge mecab-ko
pip install python-mecab-ko
```

# faiss ë³„ë„ ì„¤ì¹˜
```bash
conda install -c conda-forge faiss-gpu 
```

# torch ë³„ë„ ì„¤ì¹˜
```bash
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

# ollama ì„¤ì¹˜
https://ollama.com/download
```

# ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

# jdk ë³„ë„ ì„¤ì¹˜ (í•˜ê¸° ì´ìŠˆ ëŒ€ì‘)
```bash
jpype._jvmfinder.JVMNotFoundException: No JVM shared library file (jvm.dll) found. Try setting up the JAVA_HOME environment variable properly.
```
conda install conda-forge::openjdk

<!-- # vllm ë³„ë„ ì„¤ì¹˜ (í•˜ê¸° ì´ìŠˆ ëŒ€ì‘)
```bash
error: could not create 'build\bdist.win-amd64\wheel\.\vllm\model_executor\layers\fused_moe\configs\E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json': No such file or directory
```
win+r -> regedit -> HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\FileSystem LongPathsEnabled -> value to 1
pip install vllm==0.8.5.post1 -->

2. config ì„¤ì •

# í•˜ë“œì›¨ì–´
```bash
hardware:
  cuda_devices: "0, 1"
```
ê°€ìš©í•  gpu ì„ íƒ

# ë°ì´í„° ê²½ë¡œ
```bash
datasets:
  corpus: "D:\\project\\llm-develop\\datasets\\hyundai\\hyundai_corpus.jsonl"
  queries: "D:\\project\\llm-develop\\datasets\\hyundai\\hyundai_queries.jsonl"
  dev: "D:\\project\\llm-develop\\datasets\\hyundai\\hyundai_dev.jsonl"
```
dataset/ í´ë”ì— ë°ì´í„°ì…‹ì„ ë„£ê±°ë‚˜, ë³„ë„ ê²½ë¡œì— ì¶”ê°€ í›„ ê²½ë¡œ ìˆ˜ì •
corpus  : ê²€ìƒ‰ì„ ì§„í–‰í•  documents
queries : ê²€ìƒ‰ì„ ìœ„í•œ queries
dev     : qid, cid ì—°ê²°ì„± ê´€ë¦¬ 

# ì„ë² ë”© ëª¨ë¸ ì •ì˜
```bash
embedding_models:
  finetune_bge_m3_3:
    name: "finetune BGE-M3"
    path: "D:\\project\\models\\bge-m3_finetune3"
    type: "flag"
```
ì„ë² ë”© ëª¨ë¸ ë¶ˆëŸ¬ì˜¬ ê²½ë¡œì™€ ë¶ˆëŸ¬ì˜¤ëŠ” class í˜•íƒœ ì •ì˜

# LLM ëª¨ë¸ ì •ì˜
```bash
llm_models:

  gemma3-4b:
    name: "gemma3-4b"
    path: "gemma3:4b"
    type: "ollamachatmodel"
    max_tokens: 512

  gemma3-4b:
    name: "gemma3-4b"
    path: "D:\\project\\models\\gemma3-4b"
    type: "customchatmodel" or "vllm"
    max_tokens: 512
```
LLM ëª¨ë¸ ë¶ˆëŸ¬ì˜¬ ê²½ë¡œì™€ ë¶ˆëŸ¬ì˜¤ëŠ” class í˜•íƒœ ë° ìµœëŒ€ ì‘ë‹µ í† í° ìˆ˜ ì •ì˜
ollama ê²½ìš° pathëŠ” servingë˜ê³  ìˆëŠ” NAME
* vllmì€ linux ìš©ë„..

# ê²€ìƒ‰ê¸°, Retrievers ì •ì˜
```bash
  faiss_finetune3:
    name: "faiss_finetune3"
    type: "faiss"
    embedding_model: "finetune_bge_m3_3"
    search_type: "mmr"
    k: 5
    instruction: True # encode_queries
  
  bm25_mecab:
    name: "bm25_mecab"
    type: "bm25"
    tokenizer: "mecab"
    k: 5
    
  # Ensemble retrievers
  ensembles:

    bc_finetune_5_5:
      name: "bc_finetune_5_5"
      retrievers: ["bm25_mecab", "faiss_finetune3"]
      weights: [0.5, 0.5]
      search_type: "mmr"
      k: 5
      c: 60.0
```
ê²€ìƒ‰ê¸° íƒ€ì… ì •ì˜ - bm25 (sparse), faiss (dense)
bm25ì˜ ê²½ìš° tokenizer í•„ìš” - retrievers/BaseRetriever.py ë‚´ tokenizer ì°¸ì¡°
faissì˜ ê²½ìš° embedding_model í•„ìš” - config ë‚´ ì •ì˜ë˜ì–´ ìˆëŠ” ì„ë² ë”© ëª¨ë¸ í˜¸ì¶œ ê°€ëŠ¥
faissì˜ ê²½ìš° instruction ì„¤ì • ê°€ëŠ¥ - ëª¨ë“  ì¿¼ë¦¬ì— ëŒ€í•œ 
faiss-ollamaì˜ ê²½ìš° pathëŠ” servingë˜ê³  ìˆëŠ” ì´ë¦„ ì‚¬ìš©
* faissëŠ” FaissRetrieverWithScores, FaissIndexRetrieverWithScores ì¤‘ Indexë¥¼ ì´ìš©í•œ í›„ì ì‚¬ìš© ì¤‘
ensembleì˜ ê²½ìš° retrievers, weights í•„ìš” - config ë‚´ ì •ì˜ë˜ì–´ ìˆëŠ” retriever í˜¸ì¶œ ê°€ëŠ¥
këŠ” ê²€ìƒ‰ê¸° ê³µí†µ ìš”ì†Œë¡œ, ê²€ìƒ‰ ê°œìˆ˜ ì •ì˜

# Reranker ì •ì˜
```bash
rerankers:
  rerank_bc_finetune_5_5:
    retriever: "bc_finetune_5_5"
    embedding_model: "reranker"
```
retriever, embedding_model í•„ìš” - config ë‚´ ì •ì˜ë˜ì–´ ìˆëŠ” retriever, embedding_model(trained for reranker) í˜¸ì¶œ ê°€ëŠ¥

# Evalaution 
```bash
evaluation:
  k: 5
  k_rerank: 5
  metrics:
    - ndcg
    - recall
    - rr
    - precision
    - hit
```
retrievers, rerankersì— ëŒ€í•´ ìœ„ 5ê°€ì§€ í•­ëª© í‰ê°€ ê°€ëŠ¥
k, k_rearnk ë¶„ë¦¬ ì´ìœ ëŠ” top_k ì— ëŒ€í•´ ë½‘ê³  ë” ì‘ì€ ë°¤ìœ„ì— ëŒ€í•´ì„œ rerank ê²°ê³¼ë¥¼ ë³´ê³  ì‹¶ì„ ê²½ìš° ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •

# Evalaution 
```bash
consistency:
  consistency_gemma3-4b:
    llm_model: gemma3-4b
    retriever: bc_finetune_5_5
    path_num: 5
    k: 5
    seed: 42
```
llm_model, retriever í•„ìš” - config ë‚´ ì •ì˜ë˜ì–´ ìˆëŠ” llm_model, retriever í˜¸ì¶œ ê°€ëŠ¥


í˜¸ì¶œ configì— ëŒ€í•œ ì„¤ëª…ë“¤ì€
D:\project\llm-V\llm-v1.4\configs\retriever_short_config.yaml
ë¥¼ ì°¸ì¡°

3. ì‹¤í–‰

<!-- # ollama êµ¬ë™
ollama serve  -->

# main ì½”ë“œ í˜¸ì¶œ / ollama ì—°ê²° ì´ìŠˆë¡œ fail
ì‹¤í–‰ì— ì•ì„œ ë‚´ë¶€ ëª¨ë¸ ê²½ë¡œ ë“±ì€ ì§ì ‘ ì…ë ¥ ë°”ëŒ.

run.py ê¸°ì¤€ ì‹¤í–‰ ì‹œ configì™€ ìƒê´€ì—†ì´ ì½”ë“œ ë‚´ index_nameì— ì˜í•´ ë°ì´í„°ë¡œë“œ ë° ê²€ìƒ‰ê¸° ì €ì¥ ë“±ì´ ì§„í–‰ë˜ë©° ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€ ì…ë ¥ì„ ì§„í–‰
local, vm serving, elasticsearch ì¤‘ ëª¨ë¸ ì„ íƒ (esëŠ” vmì—ì„œë§Œ ê°€ëŠ¥)
ì‹¤ì œ ì‚¬ìš©í•  documentë¥¼ ë§Œë“¤ê¸° ìœ„í•œ ì»¬ëŸ¼ ì„ íƒ ë° ì¶”ê°€ enrich ì„ íƒ (tokenizer ê¸°ë°˜ enrich, llm ê¸°ë°˜ enrich, no enrich ì¤‘)
chunk ì‹œ ì‚¬ì´ì¦ˆ ì„ íƒ (ë°ì´í„° ì „ì²˜ë¦¬)
ê¸°ì¡´ì— ìˆëŠ” datasetë‚´ ì¡´ì¬í•˜ëŠ” ì¿¼ë¦¬ë§Œ ì“¸ì§€ ì„ íƒ (query ìµœì í™”, ìƒˆë¡œìš´ ì¿¼ë¦¬ ì‚¬ìš©í•  ê²½ìš° n)
```bash
python run.py
python test.py --test {num} --dir {num}

```

4. ë°ì´í„°ì…‹

hyundai_qwen_11 : Benchmark Q&A sheet ì— ì¡´ì¬í•˜ëŠ” ì§ˆë¬¸ / ë‹µë³€(QwQ) 1:1 
hyundai_llm_1n : 19000ê°œ ì´ìƒ ë°ì´í„°ë¥¼ corpusë¡œ êµ¬ì„±. query/corpus id ë§¤ì¹­ì€ Q&A sheet ì •ë³´ ì´ìš©
hyundai_llm_1n_short : Q&A sheet ì— ì¡´ì¬í•˜ëŠ” idë§Œì„ corpusë¡œ êµ¬ì„±. query/corpus id ë§¤ì¹­ì€ Q&A sheet ì •ë³´ ì´ìš©

5. ê¸°íƒ€

- vm ì„œë¹™ì¤‘ì¸ ëª¨ë¸ë“¤ ì‚¬ìš© ì‹œ ê°„í˜¹ ë¼ì§€í† í° ì¿¼ë¦¬ì— ëŒ€í•œ ì„ë² ë”©ì´ ì˜ ë™ì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì¡´ì¬í•¨ (ì´ìœ  í™•ì¸ í•„ìš” -> ì˜¤ë˜ ê±¸ë¦´ ì‹œ ë””ë²„ê¹… í•´ë³¼ê²ƒ ê¶Œì¥)
- -> í˜„ì¬ batch_sizeë¥¼ try í•´ë³´ë©´ì„œ ë™ì‘ batch_sizeë¥¼ ì°¾ì•„ê°€ë„ë¡ í•˜ì˜€ìœ¼ë‚˜ vm ëŒ€ë¹„ ì ì€ ìˆ˜ì˜ batch_sizeë¡œ ë™ì‘í•¨

- Elastic Search í•­ëª©ë“¤ë„ run.py ë° test.py ë‚´ í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜, ì¼ë¶€ ingest function ë“±ì€ vm ì•ˆì—ì„œê°€ ì•„ë‹ˆë©´ ì§„í–‰ ë¶ˆê°€ëŠ¥.

- utils/compute_metrics ë‚´ 'nDCG ê³„ì‚°' ìª½ í™•ì¸ ì‹œ ê³„ì‚° ë°©ë²• ë‘ê°€ì§€ ì¡´ì¬í•¨
- 1ë²ˆ https://bge-model.com/tutorial/4_Evaluation/4.1.1.html ì°¸ì¡° (iDCGë¥¼ ì˜ˆì¸¡í•œ ê²€ìƒ‰ ë¬¸ì„œì—ì„œ ìµœëŒ€ ê°’ìœ¼ë¡œ ê³„ì‚°)
- 2ë²ˆ https://bge-model.com/tutorial/4_Evaluation/4.1.1.html ì°¸ì¡° (iDCGë¥¼ ì „ì²´ ì½”í¼ìŠ¤ ìƒì—ì„œ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ìµœëŒ€ ê°’ìœ¼ë¡œ ê³„ì‚°)